{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d6v-OELUp-Dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e76b37-744c-4300-e746-f9623015d9f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8oCIJeQ_pdsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bdb7592-a133-4380-ad6f-0f2b190c2797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# 1.1 Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re # Regular expressions for text cleaning\n",
        "import nltk # Natural Language Toolkit\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer # Optional: for stemming\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import joblib # To save/load models and vectorizer (optional)\n",
        "\n",
        "# Download necessary NLTK data (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "print(\"Libraries imported successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Machine_Learning/IMDB_Dataset.csv')\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'IMDB Dataset.csv' not found. Please download it from Kaggle and place it in the correct directory.\")\n",
        "    # You might want to exit or handle this error more robustly\n",
        "    exit() # Simple exit if file not found\n",
        "\n",
        "# Display basic info and first few rows\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Map sentiment labels to numerical values\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "print(\"\\nSentiment value counts (1: positive, 0: negative):\")\n",
        "print(df['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1yC3LeibJpU",
        "outputId": "b6e76799-0d23-45a2-d37c-f30ecaf495dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n",
            "\n",
            "First 5 rows:\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "\n",
            "Sentiment value counts (1: positive, 0: negative):\n",
            "sentiment\n",
            "1    25000\n",
            "0    25000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "# ps = PorterStemmer() # Initialize stemmer if using\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove punctuation and numbers, keep only letters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize (split into words) and remove stop words\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    # Optional: Stemming\n",
        "    # words = [ps.stem(word) for word in words]\n",
        "    # Join words back into a string\n",
        "    text = ' '.join(words)\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to the 'review' column\n",
        "print(\"\\nPreprocessing text data... (This may take a few minutes)\")\n",
        "# Create a new column for cleaned reviews\n",
        "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
        "print(\"Text preprocessing complete.\")\n",
        "\n",
        "# Display original vs cleaned review for one example\n",
        "print(\"\\nExample Preprocessing:\")\n",
        "print(\"Original:\", df['review'][0][:200] + \"...\") # Show first 200 chars\n",
        "print(\"Cleaned:\", df['cleaned_review'][0][:200] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqXt1jL7bNAk",
        "outputId": "a91736a5-e11c-4c92-eb12-c043dab1c7cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessing text data... (This may take a few minutes)\n",
            "Text preprocessing complete.\n",
            "\n",
            "Example Preprocessing:\n",
            "Original: One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me abo...\n",
            "Cleaned: one reviewers mentioned watching oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['cleaned_review']\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "# stratify=y ensures the proportion of positive/negative reviews is similar in train and test sets\n",
        "\n",
        "print(f\"\\nData Split:\")\n",
        "print(f\"Training set size: {len(X_train)} samples\")\n",
        "print(f\"Testing set size: {len(X_test)} samples\")\n",
        "\n",
        "# 3.2 TF-IDF Vectorization\n",
        "# Initialize TF-IDF Vectorizer\n",
        "# max_features limits the vocabulary size to the most frequent terms, useful for large datasets\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000) # You can tune max_features\n",
        "\n",
        "# Fit the vectorizer on the training data and transform the training data\n",
        "print(\"\\nFitting TF-IDF Vectorizer and transforming training data...\")\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using the *same* fitted vectorizer\n",
        "print(\"Transforming test data...\")\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF transformation complete.\")\n",
        "print(f\"Shape of TF-IDF matrix (Train): {X_train_tfidf.shape}\") # (num_samples, num_features)\n",
        "print(f\"Shape of TF-IDF matrix (Test): {X_test_tfidf.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C4pTFF5bRdN",
        "outputId": "c8fed6f5-5232-4325-c816-9ed04fd4aef3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data Split:\n",
            "Training set size: 37500 samples\n",
            "Testing set size: 12500 samples\n",
            "\n",
            "Fitting TF-IDF Vectorizer and transforming training data...\n",
            "Transforming test data...\n",
            "TF-IDF transformation complete.\n",
            "Shape of TF-IDF matrix (Train): (37500, 5000)\n",
            "Shape of TF-IDF matrix (Test): (12500, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(C=1.0, max_iter=1000, random_state=42, solver='liblinear') # liblinear is good for binary classification with larger datasets\n",
        "\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "log_reg.fit(X_train_tfidf, y_train)\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7OJxyGRbVVl",
        "outputId": "7869d6e2-6445-434a-f918-98ccb7b621e2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression model...\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nEvaluating model on the test set...\")\n",
        "y_pred = log_reg.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Display confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Format:\n",
        "# [[TN, FP],\n",
        "#  [FN, TP]]\n",
        "\n",
        "# Display classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Negative (0)', 'Positive (1)']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xobkN6UHbZDk",
        "outputId": "242b01b5-7434-4745-dbcb-26c8ebd560f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model on the test set...\n",
            "\n",
            "Accuracy: 0.8882\n",
            "\n",
            "Confusion Matrix:\n",
            "[[5501  749]\n",
            " [ 648 5602]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Negative (0)       0.89      0.88      0.89      6250\n",
            "Positive (1)       0.88      0.90      0.89      6250\n",
            "\n",
            "    accuracy                           0.89     12500\n",
            "   macro avg       0.89      0.89      0.89     12500\n",
            "weighted avg       0.89      0.89      0.89     12500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_reviews = [\n",
        "    \"This movie was absolutely fantastic! The acting was superb and the storyline kept me engaged throughout.\",\n",
        "    \"What a waste of time. The plot was predictable and the characters were incredibly boring. I would not recommend this film.\",\n",
        "    \"It was an okay movie, not great but not terrible either. Some good moments but overall quite average.\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- Testing on New Reviews ---\")\n",
        "\n",
        "# Preprocess the new reviews\n",
        "cleaned_new_reviews = [preprocess_text(review) for review in new_reviews]\n",
        "print(\"Cleaned Reviews:\", cleaned_new_reviews)\n",
        "\n",
        "# Transform using the fitted TF-IDF vectorizer\n",
        "new_reviews_tfidf = tfidf_vectorizer.transform(cleaned_new_reviews)\n",
        "print(\"Shape of TF-IDF for new reviews:\", new_reviews_tfidf.shape)\n",
        "\n",
        "# Predict sentiment\n",
        "new_predictions = log_reg.predict(new_reviews_tfidf)\n",
        "sentiment_labels = {1: 'Positive', 0: 'Negative'}\n",
        "\n",
        "# Print results\n",
        "for review, prediction in zip(new_reviews, new_predictions):\n",
        "    print(f\"\\nReview: \\\"{review[:100]}...\\\"\")\n",
        "    print(f\"Predicted Sentiment: {sentiment_labels[prediction]} ({prediction})\")\n",
        "\n",
        "print(\"\\n--- Project Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYsF-Nh6bcr1",
        "outputId": "77218b72-b27b-4c4a-eba2-07cc2043a6df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing on New Reviews ---\n",
            "Cleaned Reviews: ['movie absolutely fantastic acting superb storyline kept engaged throughout', 'waste time plot predictable characters incredibly boring would recommend film', 'okay movie great terrible either good moments overall quite average']\n",
            "Shape of TF-IDF for new reviews: (3, 5000)\n",
            "\n",
            "Review: \"This movie was absolutely fantastic! The acting was superb and the storyline kept me engaged through...\"\n",
            "Predicted Sentiment: Positive (1)\n",
            "\n",
            "Review: \"What a waste of time. The plot was predictable and the characters were incredibly boring. I would no...\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "Review: \"It was an okay movie, not great but not terrible either. Some good moments but overall quite average...\"\n",
            "Predicted Sentiment: Negative (0)\n",
            "\n",
            "--- Project Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A12QRCNobfoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}